{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galaxies-Classification-By-Using-Deep-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 서론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN(Convolution Neural Network)은 합성곱 계층(convolutional layer)과 풀링 계층(pooling layer), 그리고 완전연결 계층(fully-connected layer)로 구성되어 특히 이미지데이터처럼 가까운 데이터끼리 서로 연관성이 높을 때 좋은 성능을 내는 모델이다. 그 구조의 예는 아래와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/Ahe2Aoo.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP에서 사용하는 완전연결 계층은 이미지 데이터를 학습하기에 문제점을 가지고 있다. 데이터의 형상이 무시된다는 것이 그것인데, 가로, 세로, 채널(색상)로 구성된 3차원 데이터인 이미지를 평평한 1차원 데이터로 평탄화해주기 때문이다. 그 다음 모든 뉴런과 연결되어 각각의 weight와 bias를 가지고 연산하기 때문에 형상을 무시하고 모든 입력 데이터를 동등한 뉴런(같은 차원의 뉴런)으로 취급한다.<br><br>\n",
    "하지만 이미지는 분명 3차원 형상이며, 따라서 공간적 정보가 중요한 요소가 된다. 서로 인접한 픽셀끼리는 유사한 값을 가지고 있다던지, 반대로 서로 거리가 먼 픽셀끼리는 큰 관련성이 없다던지, RGB채널 각각은 서로 밀접한 관련이 있다는 등 수많은 공간적 정보가 존재한다. 따라서 완전연결 계층만으로는 해결할 수 없었던 문제를 해결해주는 방법이 CNN이다.<br><br>\n",
    "Convolution Layer는 합성곱 계층과 풀링 계층으로 이루어져 있다. 합성곱 계층은 채널별로 filter를 가지고 있는데, 이 filter를 이용해 feature map과 합성곱을 통해 output을 도출하고 backpropagation을 통해 filter의 weight들을 학습시킨다. 이 filter는 n by n의 정사각형 형태이기 때문에 합성곱을 할 때 주위 인접한 데이터들을 기준으로 하기 때문에 공간적 정보를 반영하여 학습을 할 수 있는 것이다. 또한 풀링 계층은 가로, 세로 방향의 공간을 줄이는 연산으로써 feature map의 중요한 정보는 최대한 보존한 채 output을 도출해낼 수 있다.<br><br>\n",
    "따라서 이번 프로젝트를 통해 CNN을 직접 구상해봄으로써 이미지 데이터를 모델에 학습 및 평가해보고 직면하는 문제점들을 해결해나가는 것을 중점으로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 프로젝트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에 수행한 프로젝트는 '딥러닝으로 은하 분류하기'이다. 이는 데이터사이언스 데이터와 문제를 해결하기 위한 질문식 가이드를 제공해주는 사이트인 DAFIT에 게시되어있는 프로젝트이다. 프로젝트 관련 설명은 아래 링크를 통해 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 프로젝트 주소<br>\n",
    "http://www.dafit.me/question/?q=YToxOntzOjEyOiJrZXl3b3JkX3R5cGUiO3M6MzoiYWxsIjt9&bmode=view&idx=2547211&t=board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 연구"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 연구는 크게 3가지 범주로 나누어 수행했다. 첫 번째는 'Tutorial and Concept'으로 DAFIT에서 제공하는 튜토리얼을 따라 수행하며 CNN을 수행하기 위한 일련의 절차들을 배운다. 두 번째는 'Pratice_Modeling'으로 CNN 개념을 바탕으로 직접 모델을 설계하고 수정하며 최고의 성능을 도출하는 모델을 생성해낸다. 세 번째는 'Pratice_VGG16'으로 기존 Image 분야에서 높은 성능을 보였던 VGG16을 가져와서 사용하면 어떤 성능이 나올지 확인한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Tutorial and Concept](https://github.com/YoonSungLee/Galaxies-Classification-By-Using-Deep-Learning/blob/master/Tutorial_and_Concept.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acc: 76.50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(50,50,3)))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tutorial에서 제공한 모델은 매우 단순한 CNN구조로써 Conv2D-Conv2D-MaxPooling2D의 Convolution layer와 Dense(128)-Dense(3)의 fully-connected layer로 이루어져있다. BatchNormalization, Dropout, EarlyStopping 등의 Overfitting을 억제하는 기법들을 사용하지 않고 모델을 학습한다면 76.5%의 정확도를 얻을 수 있다. 이는 4개의 이미지 중에 1개는 틀린다는 의미로 성능이 그닥 좋지 않은 모델이라고 할 수 있겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Pratice Modeling](https://github.com/YoonSungLee/Galaxies-Classification-By-Using-Deep-Learning/blob/master/Pratice_Modeling.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy : 85.62%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* AI Innovation Square에서 배운 CNN의 몇 가지 모델링 기법을 적용했다.\n",
    "* feature map이 홀수가 되는 것을 방지하기 위해 첫 번째 Convolution Layer는 1개만 쌓는 방식을 택했다.\n",
    "* 과적합을 방지하고 정규화를 위해 Convolution Layer 사이에 BatchNormalization을 적용했다.\n",
    "* 기존의 CNN에서 feature map을 flatten하는 방식이 비효율적이라고 판단하여 새롭게 등장한 방법인 GlobalAveragePoolin2D를 적용하여 마지막 Layer와 연결했다(이는 각 feature map의 평균을 구해서 flatten처럼 길게 배열).\n",
    "* 마지막 Layer에서 Dense Layer를 더 추가하지 않았다. 만약 추가한다면 Dense Layer 사이에 Dropout을 이용하여 과적합을 방지하는 전략을 써야 할 것이다.\n",
    "* Convolution Layer : activation='relu'(CNN에서 좋은 효과를 보이는 활성화함수 적용)\n",
    "* Convolution Layer : kernel_initializer='he_normal'(activation function을 relu로 설정했기 때문)\n",
    "* Dense Layer : activation='softmax'(다중 분류문제이기 때문)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d_11 (Conv2D)           (None, 48, 48, 32)        896       \n",
    "_________________________________________________________________\n",
    "batch_normalization_7 (Batch (None, 48, 48, 32)        128       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_7 (MaxPooling2 (None, 24, 24, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_12 (Conv2D)           (None, 22, 22, 32)        9248      \n",
    "_________________________________________________________________\n",
    "conv2d_13 (Conv2D)           (None, 20, 20, 64)        18496     \n",
    "_________________________________________________________________\n",
    "batch_normalization_8 (Batch (None, 20, 20, 64)        256       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_8 (MaxPooling2 (None, 10, 10, 64)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_14 (Conv2D)           (None, 8, 8, 64)          36928     \n",
    "_________________________________________________________________\n",
    "conv2d_15 (Conv2D)           (None, 6, 6, 128)         73856     \n",
    "_________________________________________________________________\n",
    "batch_normalization_9 (Batch (None, 6, 6, 128)         512       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_9 (MaxPooling2 (None, 3, 3, 128)         0         \n",
    "_________________________________________________________________\n",
    "global_average_pooling2d_3 ( (None, 128)               0         \n",
    "_________________________________________________________________\n",
    "dense_3 (Dense)              (None, 3)                 387       \n",
    "=================================================================\n",
    "Total params: 140,707\n",
    "Trainable params: 140,259\n",
    "Non-trainable params: 448\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/RyCdg1r.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* best_model-06-0.89.h5\n",
    "* 모델 학습곡선을 살펴보면 train data에 대해서는 꾸준한 학습을 보이는 데 반해, validation data에 대해서는 결과값들이 들쭉날쭉하고 좋은 성능을 보이지 못하고 있다.\n",
    "* fully-connected layer의 층을 두껍게 하고 Dropout을 추가하는 방법을 적용해볼 수 있다. 추가적으로 GlobalAveragePooling2D의 적용이 이 데이터셋에 대해서는 좋지 않은 성능을 보일 수 있으므로 단순히 Flatten을 적용하는 방법도 고려해볼 수 있다.\n",
    "* 학습 조기종료가 상대적으로 빨리 이루어진듯한 느낌이 있다. 이는 Overfitting이 너무 빨리 이루어졌거나 Local Minimum Problem일 가능성이 있다. 이를 좀 더 잘 판단하기 위해 EarlyStopping의 patience을 조정해줄 필요가 있다.\n",
    "* 위의 Feedback을 했는데도 큰 발전이 없다면 Convolution Layer의 구조를 바꿀 수 밖에 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy : 86.88%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* fully-connected layer에 Dense Layer와 Dropout 2개를 추가했다.\n",
    "* EarlyStopping의 patience을 20으로 늘려 학습 조기종료시간을 조금 더 늦췄다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d_16 (Conv2D)           (None, 48, 48, 32)        896       \n",
    "_________________________________________________________________\n",
    "batch_normalization_10 (Batc (None, 48, 48, 32)        128       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_10 (MaxPooling (None, 24, 24, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_17 (Conv2D)           (None, 22, 22, 32)        9248      \n",
    "_________________________________________________________________\n",
    "conv2d_18 (Conv2D)           (None, 20, 20, 64)        18496     \n",
    "_________________________________________________________________\n",
    "batch_normalization_11 (Batc (None, 20, 20, 64)        256       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_11 (MaxPooling (None, 10, 10, 64)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_19 (Conv2D)           (None, 8, 8, 64)          36928     \n",
    "_________________________________________________________________\n",
    "conv2d_20 (Conv2D)           (None, 6, 6, 128)         73856     \n",
    "_________________________________________________________________\n",
    "batch_normalization_12 (Batc (None, 6, 6, 128)         512       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_12 (MaxPooling (None, 3, 3, 128)         0         \n",
    "_________________________________________________________________\n",
    "global_average_pooling2d_4 ( (None, 128)               0         \n",
    "_________________________________________________________________\n",
    "dense_4 (Dense)              (None, 128)               16512     \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 128)               0         \n",
    "_________________________________________________________________\n",
    "dense_5 (Dense)              (None, 128)               16512     \n",
    "_________________________________________________________________\n",
    "dropout_2 (Dropout)          (None, 128)               0         \n",
    "_________________________________________________________________\n",
    "dense_6 (Dense)              (None, 3)                 387       \n",
    "=================================================================\n",
    "Total params: 173,731\n",
    "Trainable params: 173,283\n",
    "Non-trainable params: 448\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/GwG7SkQ.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* best_model2-09-0.87.h5\n",
    "* Model 1과 비교하여 아주 미세하게 튀는 현상이 줄긴 했지만 여전히 validation data에 대해서 불안정한 결과가 많이 보인다.\n",
    "* fully-connected layer의 층을 쌓은 효과를 보지 못했다. 다른 방법으로는 GlobalAveragePooling2D 대신에 단순히 Flatten을 적용하여 feature map을 1차원 데이터로 펼치는 방법이다. GlobalAveragePooling2D이 Flatten보다 이미지 데이터에 대하여 좋은 성능을 보인다고는 하지만 모델링 방법에 따라 그리고 이미지 데이터의 특성에 따라 얼마든지 예외인 경우가 있을 수 있다.\n",
    "* 또한 마찬가지로 Overfitting 또는 Local Minimum Problem 등의 문제로 적은 수의 epoch으로 학습 조기 중단이 발생했다. 파라미터를 미세하게 수정할 필요가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy : 85.00%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d_1 (Conv2D)            (None, 48, 48, 32)        896       \n",
    "_________________________________________________________________\n",
    "batch_normalization_1 (Batch (None, 48, 48, 32)        128       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 32)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 22, 22, 32)        9248      \n",
    "_________________________________________________________________\n",
    "conv2d_3 (Conv2D)            (None, 20, 20, 64)        18496     \n",
    "_________________________________________________________________\n",
    "batch_normalization_2 (Batch (None, 20, 20, 64)        256       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 64)        0         \n",
    "_________________________________________________________________\n",
    "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
    "_________________________________________________________________\n",
    "conv2d_5 (Conv2D)            (None, 6, 6, 128)         73856     \n",
    "_________________________________________________________________\n",
    "batch_normalization_3 (Batch (None, 6, 6, 128)         512       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 128)         0         \n",
    "_________________________________________________________________\n",
    "conv2d_6 (Conv2D)            (None, 1, 1, 128)         147584    \n",
    "_________________________________________________________________\n",
    "batch_normalization_4 (Batch (None, 1, 1, 128)         512       \n",
    "_________________________________________________________________\n",
    "flatten_1 (Flatten)          (None, 128)               0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 128)               16512     \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 128)               0         \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 128)               16512     \n",
    "_________________________________________________________________\n",
    "dropout_2 (Dropout)          (None, 128)               0         \n",
    "_________________________________________________________________\n",
    "dense_3 (Dense)              (None, 3)                 387       \n",
    "=================================================================\n",
    "Total params: 321,827\n",
    "Trainable params: 321,123\n",
    "Non-trainable params: 704\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/qYlysiJ.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* best_model3-13-0.85.h5\n",
    "* Model 2와 비교하여 학습곡선이 더욱 불안정하고 val_loss와 val_acc 또한 더 좋지 않은 결과를 보이고 있다. 이로써 Flatten보다는 GlobalAveragePooling2D가 더 좋은 효과를 낸다는 것을 확인할 수 있었다.\n",
    "* fully-connected layer에서 문제가 없다면 결국 Convolution Layer를 손댈 수 밖에 없다. Image 분야에서 좋은 성능을 낸 모델들의 구성과 비슷하게 만들어보는 방법이 있고, 그냥 그 모델 그대로 가져와서 학습하는 방법이 있다. 모델링에 초점을 맞추어 Convolution Layer의 구성을 바꾸는 방법을 택하기로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy : 87.29%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 한때 Image데이터에 대단한 성능을 보였던 VGG16 모델을 개조한 모델이다.\n",
    "* VGG16은 input data의 shape이 (224,224)로 고정되어있으므로 ImageDataGenerator 인스턴스들의 target_size를 알맞게 조정해준다.\n",
    "* 모든 layer의 activation function을 'relu'로, kernel initializer를 'he_normal'로 설정했다.\n",
    "* Convolution - Convolution - MaxPooling을 한 블록이라고 한다면, 블록과 블록 사이에 BatchNormalization을 적용하여 모델의 성능을 높이고자 했다.\n",
    "* 기존 VGG16의 bottleneck을 완화하기 위해 Maxpooling2D를 하기 전에 filter의 수를 미리 2배로 늘려주었다.\n",
    "* 기존 VGG16의 fully-connected layer의 Flatten 대신 GlobalAveragePooling2D를 사용하고, 이에 따라 Dense layer의 units 또한 적절히 수정했다.\n",
    "* fully-connected layer의 Dense layer 사이에 Dropout을 적용하여 Dense layer들의 Overfitting을 방지하고자 했다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d_1 (Conv2D)            (None, 224, 224, 64)      1792      \n",
    "_________________________________________________________________\n",
    "conv2d_2 (Conv2D)            (None, 224, 224, 128)     73856     \n",
    "_________________________________________________________________\n",
    "batch_normalization_1 (Batch (None, 224, 224, 128)     512       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 128)     0         \n",
    "_________________________________________________________________\n",
    "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
    "_________________________________________________________________\n",
    "conv2d_4 (Conv2D)            (None, 112, 112, 256)     295168    \n",
    "_________________________________________________________________\n",
    "batch_normalization_2 (Batch (None, 112, 112, 256)     1024      \n",
    "_________________________________________________________________\n",
    "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 256)       0         \n",
    "_________________________________________________________________\n",
    "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
    "_________________________________________________________________\n",
    "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
    "_________________________________________________________________\n",
    "conv2d_7 (Conv2D)            (None, 56, 56, 512)       1180160   \n",
    "_________________________________________________________________\n",
    "batch_normalization_3 (Batch (None, 56, 56, 512)       2048      \n",
    "_________________________________________________________________\n",
    "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 512)       0         \n",
    "_________________________________________________________________\n",
    "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "conv2d_10 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "batch_normalization_4 (Batch (None, 28, 28, 512)       2048      \n",
    "_________________________________________________________________\n",
    "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 512)       0         \n",
    "_________________________________________________________________\n",
    "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "conv2d_13 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
    "_________________________________________________________________\n",
    "batch_normalization_5 (Batch (None, 14, 14, 512)       2048      \n",
    "_________________________________________________________________\n",
    "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 512)         0         \n",
    "_________________________________________________________________\n",
    "global_average_pooling2d_1 ( (None, 512)               0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 512)               262656    \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 512)               0         \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 512)               262656    \n",
    "_________________________________________________________________\n",
    "dropout_2 (Dropout)          (None, 512)               0         \n",
    "_________________________________________________________________\n",
    "dense_3 (Dense)              (None, 3)                 1539      \n",
    "=================================================================\n",
    "Total params: 17,572,099\n",
    "Trainable params: 17,568,259\n",
    "Non-trainable params: 3,840\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/Yj6r5Iu.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* best_model4-25-0.91.h5\n",
    "* ModelCheckpoint를 통해 저장된 모델을 기준으로 했을 때 이전 모델들에 비해서 좋은 성능을 낸 것은 맞다. 하지만 학습곡선을 두고 봤을 땐 오히려 더 불안정한 경향이 있다. 쌓은 layer에 비해 큰 성능을 내지 못하고 있다.\n",
    "* AI Innovation Square에서 배운 내용을 바탕으로 한 가지 모델을 더 실험할 계획이다. 먼저 모든 Convolution가 통과된 이후 BatchNormalization을 적용시킨다. 또한 BatchNormalization의 파라미터가 Convolution Layer의 bias 역할을 대신 해주므로 모든 Convolution Layer의 bias를 제거시켜준다(use_bias=False).\n",
    "* 추가적으로 EarlyStopping이 너무 늦다고 판단하여 patience 조절이 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Model 4의 Convolution Layer의 구조를 Conv2D-BN-Conv2D-BN-MaxPooling2D 형식으로 바꾼다.\n",
    "* Convolution Layer의 bias를 제거시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d_14 (Conv2D)           (None, 224, 224, 64)      1728      \n",
    "_________________________________________________________________\n",
    "batch_normalization_14 (Batc (None, 224, 224, 64)      256       \n",
    "_________________________________________________________________\n",
    "conv2d_15 (Conv2D)           (None, 224, 224, 128)     73728     \n",
    "_________________________________________________________________\n",
    "batch_normalization_15 (Batc (None, 224, 224, 128)     512       \n",
    "_________________________________________________________________\n",
    "max_pooling2d_6 (MaxPooling2 (None, 112, 112, 128)     0         \n",
    "_________________________________________________________________\n",
    "conv2d_16 (Conv2D)           (None, 112, 112, 128)     147456    \n",
    "_________________________________________________________________\n",
    "batch_normalization_16 (Batc (None, 112, 112, 128)     512       \n",
    "_________________________________________________________________\n",
    "conv2d_17 (Conv2D)           (None, 112, 112, 256)     294912    \n",
    "_________________________________________________________________\n",
    "batch_normalization_17 (Batc (None, 112, 112, 256)     1024      \n",
    "_________________________________________________________________\n",
    "max_pooling2d_7 (MaxPooling2 (None, 56, 56, 256)       0         \n",
    "_________________________________________________________________\n",
    "conv2d_18 (Conv2D)           (None, 56, 56, 256)       589824    \n",
    "_________________________________________________________________\n",
    "batch_normalization_18 (Batc (None, 56, 56, 256)       1024      \n",
    "_________________________________________________________________\n",
    "conv2d_19 (Conv2D)           (None, 56, 56, 256)       589824    \n",
    "_________________________________________________________________\n",
    "batch_normalization_19 (Batc (None, 56, 56, 256)       1024      \n",
    "_________________________________________________________________\n",
    "conv2d_20 (Conv2D)           (None, 56, 56, 512)       1179648   \n",
    "_________________________________________________________________\n",
    "batch_normalization_20 (Batc (None, 56, 56, 512)       2048      \n",
    "_________________________________________________________________\n",
    "max_pooling2d_8 (MaxPooling2 (None, 28, 28, 512)       0         \n",
    "_________________________________________________________________\n",
    "conv2d_21 (Conv2D)           (None, 28, 28, 512)       2359296   \n",
    "_________________________________________________________________\n",
    "batch_normalization_21 (Batc (None, 28, 28, 512)       2048      \n",
    "_________________________________________________________________\n",
    "conv2d_22 (Conv2D)           (None, 28, 28, 512)       2359296   \n",
    "_________________________________________________________________\n",
    "batch_normalization_22 (Batc (None, 28, 28, 512)       2048      \n",
    "_________________________________________________________________\n",
    "conv2d_23 (Conv2D)           (None, 28, 28, 512)       2359296   \n",
    "_________________________________________________________________\n",
    "batch_normalization_23 (Batc (None, 28, 28, 512)       2048      \n",
    "_________________________________________________________________\n",
    "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 512)       0         \n",
    "_________________________________________________________________\n",
    "conv2d_24 (Conv2D)           (None, 14, 14, 512)       2359296   \n",
    "_________________________________________________________________\n",
    "batch_normalization_24 (Batc (None, 14, 14, 512)       2048      \n",
    "_________________________________________________________________\n",
    "conv2d_25 (Conv2D)           (None, 14, 14, 512)       2359296   \n",
    "_________________________________________________________________\n",
    "batch_normalization_25 (Batc (None, 14, 14, 512)       2048      \n",
    "_________________________________________________________________\n",
    "conv2d_26 (Conv2D)           (None, 14, 14, 512)       2359296   \n",
    "_________________________________________________________________\n",
    "batch_normalization_26 (Batc (None, 14, 14, 512)       2048      \n",
    "_________________________________________________________________\n",
    "max_pooling2d_10 (MaxPooling (None, 7, 7, 512)         0         \n",
    "_________________________________________________________________\n",
    "global_average_pooling2d_2 ( (None, 512)               0         \n",
    "_________________________________________________________________\n",
    "dense_4 (Dense)              (None, 512)               262656    \n",
    "_________________________________________________________________\n",
    "dropout_3 (Dropout)          (None, 512)               0         \n",
    "_________________________________________________________________\n",
    "dense_5 (Dense)              (None, 512)               262656    \n",
    "_________________________________________________________________\n",
    "dropout_4 (Dropout)          (None, 512)               0         \n",
    "_________________________________________________________________\n",
    "dense_6 (Dense)              (None, 3)                 1539      \n",
    "=================================================================\n",
    "Total params: 17,578,435\n",
    "Trainable params: 17,569,091\n",
    "Non-trainable params: 9,344\n",
    "_________________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/0lHwbRR.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* best_model5-21-0.85.h5\n",
    "* 전체적인 val_loss가 조금씩 줄어든 양상이 보이긴 하나 그 차이가 미세하다. 그래도 효과는 어느 정도 있기 때문에 모든 Convolution Layer 다음에 BatchNormalization을 적용하는 것은 바람직한 방법이라 생각한다. 이에 따라 Convolution Layer의 bias를 사용하지 않도록 설정하는 것 또한 상기시켜야 할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test set의 정확도 결과는 위의 내용과 같다. 가장 낮은 정확도를 도출한 모델은 Model 5(84.79%)이고, 가장 높은 정확도를 도출한 모델은 Model 4(89.29%)이다. 이 결과를 놓고 보면 validation set을 통한 모델들의 기대성능과는 또다른 결과라고 할 수 있겠다. Model 4의 성능이 나쁘지 않아 BatchNormalization을 더 추가하고 Convolution Layer의 use_bias를 False로 설정하면 Model 5의 성능이 더 좋을 것이다라고 추측했는데, 실상은 오히려 가장 낮은 정확도를 보이기 때문이다. 이 원인에는 여러가지가 존재한다. validation set을 통한 평가결과가 운이 좋게 나온것일수도 있고, best_model의 기준을 accuracy가 아닌 loss로 설정한 탓일수도 있다. 또는 이번 test set에서만 유독 성능이 좋지 않을수도 있다. 하지만 중요한 점은 지금 내 관점으로는 정확한 원인 규명이 어렵고 모델의 성능을 더욱 좋게 할 수 있는 방도가 쉽게 떠오르지 않는다는 점이다. 이는 실무적인 면과 이론적인 면에서 모두 실력을 더 키워야 한다는 것을 반증한다.<br>\n",
    "추가적으로 이번 모델링을 할 때에는 하이퍼파라미터들에 대해 깊이 신경쓰지 않고 모델링에 중점을 두었다. 최적의 하이퍼파라미터 탐색도 하나의 중요한 이슈이므로 더욱 모델의 성능을 올리고 싶으면 이 또한 신경써줘야 하는 부분이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 고찰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "model 5 accuracy : 84.79%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
